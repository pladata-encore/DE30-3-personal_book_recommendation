{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4e3b9ba-d6c9-4a18-a98b-4628aa4c07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "키워드를 입력하세요:  책\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'책' 키워드를 가장 많이 포함하는 상위 5개 ISBN:\n",
      "['9791158510619.0', '9791162540640.0', '9791158883591.0', '9788932473901.0', '9788937834790.0']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "# CSV 파일 경로\n",
    "file_path = 'merged_df.csv'\n",
    "# 키워드 입력\n",
    "keyword = input(\"키워드를 입력하세요: \")\n",
    "# introduction 컬럼에서 키워드를 가장 많이 포함하는 값을 찾기 위해 Counter 사용\n",
    "keyword_counts = Counter()\n",
    "# CSV 파일 열기\n",
    "with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    headers = next(reader)  # 헤더 스킵\n",
    "    keyword_index = headers.index('introduction')  # introduction 컬럼의 인덱스 찾기\n",
    "    # 행마다 introduction 컬럼의 값을 확인하여 키워드가 포함되어 있는지 확인\n",
    "    for row in reader:\n",
    "        introduction_text = row[keyword_index]\n",
    "        if keyword.lower() in introduction_text.lower():\n",
    "            isbn = row[headers.index('isbn')]\n",
    "            keyword_counts[isbn] += 1\n",
    "# 가장 많은 키워드를 가진 상위 5개의 ISBN 찾기\n",
    "top_5_isbn = [isbn for isbn, _ in keyword_counts.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7a96756-c22a-4d5d-bfd0-4aa5566b0265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                isbn                         title\n",
      "75   9788937834790.0                      정의란 무엇인가\n",
      "151  9791158510619.0             타이탄의 도구들 (블랙 에디션)\n",
      "468  9791162540640.0                   아주 작은 습관의 힘\n",
      "774  9791158883591.0  부자 아빠 가난한 아빠 1 (20주년 특별 기념판)\n",
      "782  9788932473901.0                       이기적 유전자\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_13900\\1563195801.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_rows = pd.concat([result_rows, matches])  # 찾은 행을 결과 데이터프레임에 추가\n"
     ]
    }
   ],
   "source": [
    "top_5_isbn = [float(isbn) for isbn in top_5_isbn]  # 문자열을 실수로 변환\n",
    "\n",
    "result_rows = pd.DataFrame(columns=df.columns)  # 결과를 저장할 빈 데이터프레임 생성\n",
    "\n",
    "for column in df.columns:\n",
    "    matches = df[df[column].isin(top_5_isbn)]  # 해당 칼럼에서 값이 리스트에 있는 행 찾기\n",
    "    result_rows = pd.concat([result_rows, matches])  # 찾은 행을 결과 데이터프레임에 추가\n",
    "\n",
    "result_subset = result_rows[['isbn', 'title']]\n",
    "result_rows = pd.DataFrame(columns=df.columns, dtype=str)\n",
    "top_5_isbn = [str(isbn) for isbn in top_5_isbn]\n",
    "\n",
    "result_subset['isbn'] = result_subset['isbn'].astype(str).str.strip()\n",
    "result_subset['title'] = result_subset['title'].str.strip()\n",
    "\n",
    "result_unique = result_subset.drop_duplicates(subset=['isbn'])\n",
    "print(result_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0cf2b72-7846-4980-9b14-31801971441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "키워드를 입력하세요:  책\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                isbn                         title\n",
      "75   9788937834790.0                      정의란 무엇인가\n",
      "151  9791158510619.0             타이탄의 도구들 (블랙 에디션)\n",
      "468  9791162540640.0                   아주 작은 습관의 힘\n",
      "774  9791158883591.0  부자 아빠 가난한 아빠 1 (20주년 특별 기념판)\n",
      "782  9788932473901.0                       이기적 유전자\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata2\\AppData\\Local\\Temp\\ipykernel_13900\\2906477010.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_rows = pd.concat([result_rows, matches])  # 찾은 행을 결과 데이터프레임에 추가\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "# CSV 파일 경로\n",
    "file_path = 'merged_df.csv'\n",
    "# 키워드 입력\n",
    "keyword = input(\"키워드를 입력하세요: \")\n",
    "# introduction 컬럼에서 키워드를 가장 많이 포함하는 값을 찾기 위해 Counter 사용\n",
    "keyword_counts = Counter()\n",
    "# CSV 파일 열기\n",
    "with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    headers = next(reader)  # 헤더 스킵\n",
    "    keyword_index = headers.index('introduction')  # introduction 컬럼의 인덱스 찾기\n",
    "    # 행마다 introduction 컬럼의 값을 확인하여 키워드가 포함되어 있는지 확인\n",
    "    for row in reader:\n",
    "        introduction_text = row[keyword_index]\n",
    "        if keyword.lower() in introduction_text.lower():\n",
    "            isbn = row[headers.index('isbn')]\n",
    "            keyword_counts[isbn] += 1\n",
    "# 가장 많은 키워드를 가진 상위 5개의 ISBN 찾기\n",
    "top_5_isbn = [isbn for isbn, _ in keyword_counts.most_common(5)]\n",
    "\n",
    "top_5_isbn = [float(isbn) for isbn in top_5_isbn]  # 문자열을 실수로 변환\n",
    "\n",
    "result_rows = pd.DataFrame(columns=df.columns)  # 결과를 저장할 빈 데이터프레임 생성\n",
    "\n",
    "for column in df.columns:\n",
    "    matches = df[df[column].isin(top_5_isbn)]  # 해당 칼럼에서 값이 리스트에 있는 행 찾기\n",
    "    result_rows = pd.concat([result_rows, matches])  # 찾은 행을 결과 데이터프레임에 추가\n",
    "\n",
    "result_subset = result_rows[['isbn', 'title']]\n",
    "result_rows = pd.DataFrame(columns=df.columns, dtype=str)\n",
    "top_5_isbn = [str(isbn) for isbn in top_5_isbn]\n",
    "\n",
    "result_subset['isbn'] = result_subset['isbn'].astype(str).str.strip()\n",
    "result_subset['title'] = result_subset['title'].str.strip()\n",
    "\n",
    "result_unique = result_subset.drop_duplicates(subset=['isbn'])\n",
    "print(result_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6436764a-6b7d-444a-911f-8ddcc358aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼을 선택하세요:\n",
      "1. 책소개\n",
      "2. 작가소개\n",
      "3. 서평\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "선택 (1/2/3):  3\n",
      "키워드를 입력하세요:  안녕\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             마음이 살짝 기운다\n",
      "1                최재천의 공부\n",
      "2     햇빛은 찬란하고 인생은 귀하니까요\n",
      "3    가장 예쁜 생각을 너에게 주고 싶다\n",
      "5             안녕, 소중한 사람\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_book(file_path):\n",
    "    import csv\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    # 사용자가 선택할 수 있는 컬럼 목록 및 한글 표시\n",
    "    column_choices = {\n",
    "        '책소개': 'introduction',\n",
    "        '작가소개': 'author_info',\n",
    "        '서평': 'book_rev'\n",
    "    }\n",
    "    # 사용자에게 선택지 제시\n",
    "    print(\"컬럼을 선택하세요:\")\n",
    "    for idx, (kor_name, eng_name) in enumerate(column_choices.items(), 1):\n",
    "        print(f\"{idx}. {kor_name}\")\n",
    "    # 사용자 입력 받기\n",
    "    choice = int(input(\"선택 (1/2/3): \"))\n",
    "    selected_column = column_choices[list(column_choices.keys())[choice - 1]]\n",
    "    # 키워드 입력\n",
    "    keyword = input(\"키워드를 입력하세요: \")\n",
    "    # CSV 파일 열기\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        # 선택된 컬럼에서 키워드를 가장 많이 포함하는 값을 찾기 위해 Counter 사용\n",
    "        keyword_counts = Counter()\n",
    "        # 행마다 선택된 컬럼의 값을 확인하여 키워드가 포함되어 있는지 확인\n",
    "        for row in reader:\n",
    "            selected_text = row[selected_column]\n",
    "            if keyword.lower() in selected_text.lower():\n",
    "                isbn = row['isbn']\n",
    "                keyword_counts[isbn] += 1\n",
    "    # 가장 많은 키워드를 가진 상위 5개의 ISBN 찾기\n",
    "    top_5_isbn = [isbn for isbn, _ in keyword_counts.most_common(5)]\n",
    "    # CSV 파일 다시 열기\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        headers = reader.fieldnames\n",
    "        # 결과를 저장할 빈 데이터프레임 생성\n",
    "        result_rows = pd.DataFrame(columns=headers, dtype=str)\n",
    "        # 행마다 top_5_isbn에 해당하는 행을 찾아서 결과 데이터프레임에 추가\n",
    "        for row in reader:\n",
    "            if row['isbn'] in top_5_isbn:\n",
    "                result_rows = pd.concat([result_rows, pd.DataFrame([row], columns=headers)], ignore_index=True)\n",
    "    # 결과 데이터프레임에서 isbn과 title 열 선택 및 중복 제거\n",
    "    result_subset = result_rows[['isbn', 'title']]\n",
    "    result_unique = result_subset.drop_duplicates(subset=['isbn'])\n",
    "    result_unique = result_unique['title']\n",
    "    return result_unique\n",
    "# 함수 실행\n",
    "result = find_book(\"C:/Users/Playdata2/Desktop/data/merged_df.csv\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d423ed02-1c7f-4c65-9d0d-1b14db9bd5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Fonts\\gulim.ttc\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager\n",
    "\n",
    "font_list = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "\n",
    "for font in font_list:\n",
    "    if 'gulim' in font:  # 나눔 폰트 확인\n",
    "        print(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3b1d3-82d1-4c95-a18c-ad8b32f81230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
